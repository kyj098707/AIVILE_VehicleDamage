{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcU1ZMuFQ0dzNknJqR4Jb/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Set up"],"metadata":{"id":"t3NYVMR38Osd"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"S4ouvvXF8TLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YeFW4gEb8Icw"},"outputs":[],"source":["# *------- Basic setup -------*\n","import numpy as np\n","import pandas as pd\n","import os, random\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import cv2\n","import glob\n","from PIL import Image\n","\n","# *------- tensorflow & keras -------*\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# *------- sklearn -------*\n","from sklearn.model_selection import train_test_split\n","\n","# *------- path & file -------*\n","dataset_path = \"/content/drive/MyDrive/KT_3차_미프/Datasets\"\n","\n","train_path = os.path.join(dataset_path, 'Car_Images_train')\n","tr_n_path = os.path.join(train_path, 'normal')\n","tr_ab_path = os.path.join(train_path, 'abnormal')\n","\n","test_path = os.path.join(dataset_path, 'Car_Images_test')\n","te_n_path = os.path.join(test_path, 'normal')\n","te_ab_path = os.path.join(test_path, 'abnormal')\n","\n","val_path = os.path.join(dataset_path, 'Car_Images_validation')\n","val_n_path = os.path.join(val_path, 'normal')\n","val_ab_path = os.path.join(val_path, 'abnormal')\n","\n","aug_dataset_path = os.path.join(dataset_path, 'aug_Dataset')"]},{"cell_type":"markdown","source":["## Prepare the dataset"],"metadata":{"id":"WstwrMr282HG"}},{"cell_type":"code","source":["import os\n","\n","def createDirectory(directory):\n","    try:\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","    except OSError:\n","        print(\"Error: Failed to create the directory.\")"],"metadata":{"id":"EdB68sHM9LOE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create Directory\n","\n","createDirectory(aug_dataset_path)"],"metadata":{"id":"oe0W45-P9S4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.preprocessing.image import img_to_array\n","\n","img_size= 280\n","\n","clear_session()\n","\n","# 이미지 및 라벨데이터 제작\n","def glos(folder):\n","    files = glob.glob(f'{dataset_path}/copy_images/{folder}/*.png')\n","    data, label = zip(*[[img_to_array(Image.open(f).resize((img_size, img_size))), 1 if os.path.split(f)[1][:2] == 'ab' else 0 ] for f in files])\n","    return np.array(list(data)), np.array(list(label))\n","\n","entire_data, entire_label = glos('*')\n","# train_data, train_label = glos('trainset')\n","# validation_data, validation_label = glos('validset')\n","# test_data, test_label = glos('testset')"],"metadata":{"id":"5MGj98eU9juU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["entire_data = entire_data.astype(\"float32\") / 255.0\n","entire_label = tf.one_hot(entire_label, 2)"],"metadata":{"id":"Ax_jzdCF9JUv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["entire_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7nuCiFEFeLU","executionInfo":{"status":"ok","timestamp":1679453207640,"user_tz":-540,"elapsed":13,"user":{"displayName":"김채원","userId":"06191165418472654659"}},"outputId":"dcc92828-35d5-4a6a-8c31-7c7d4bba7d8a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(605, 280, 280, 3)"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["AUTO = tf.data.AUTOTUNE\n","BATCH_SIZE = 256\n","EPOCHS = 10"],"metadata":{"id":"dv3WIunJ9eVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_samples = 121\n","\n","x_test, y_test = entire_data[:test_samples], entire_label[:test_samples]\n","new_x_train, new_y_train = entire_data[test_samples:], entire_label[test_samples:]\n","\n","train_ds_one = (\n","    tf.data.Dataset.from_tensor_slices((new_x_train, new_y_train))\n","    .shuffle(BATCH_SIZE * 100)\n","    .batch(BATCH_SIZE)\n",")\n","train_ds_two = (\n","    tf.data.Dataset.from_tensor_slices((new_x_train, new_y_train))\n","    .shuffle(BATCH_SIZE * 100)\n","    .batch(BATCH_SIZE)\n",")\n","# Because we will be mixing up the images and their corresponding labels, we will be\n","# combining two shuffled datasets from the same training data.\n","train_ds = tf.data.Dataset.zip((train_ds_one, train_ds_two))\n","\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"],"metadata":{"id":"tej3wny99eYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n","    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n","    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n","    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n","\n","\n","def mix_up(ds_one, ds_two, alpha=0.2):\n","    # Unpack two datasets\n","    images_one, labels_one = ds_one\n","    images_two, labels_two = ds_two\n","    batch_size = tf.shape(images_one)[0]\n","\n","    # Sample lambda and reshape it to do the mixup\n","    l = sample_beta_distribution(batch_size, alpha, alpha)\n","    x_l = tf.reshape(l, (batch_size, 1, 1, 1))\n","    y_l = tf.reshape(l, (batch_size, 1))\n","\n","    # Perform mixup on both images and labels by combining a pair of images/labels\n","    # (one from each dataset) into one image/label\n","    images = images_one * x_l + images_two * (1 - x_l)\n","    labels = labels_one * y_l + labels_two * (1 - y_l)\n","    return (images, labels)"],"metadata":{"id":"1f0EMMm39ebX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds_mu = train_ds.map(\n","    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2), num_parallel_calls=AUTO\n",")\n","\n","sample_images, sample_labels = next(iter(train_ds_mu))\n","\n","mix_data = []\n","mix_label = []\n","\n","for i, (image, label) in enumerate(zip(sample_images, sample_labels)):\n","    if label.numpy().tolist()[0] >= 0.95: #정상\n","        mix_data.append(image.numpy())\n","        mix_label.append([0])\n","    else:\n","        mix_data.append(image.numpy())\n","        mix_label.append([1])\n","\n","mix_data, mix_label = np.array(list(mix_data)), np.array(list(mix_label))"],"metadata":{"id":"v5hmFwZqCg8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mix_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tgxr_cjChE0","executionInfo":{"status":"ok","timestamp":1679453337503,"user_tz":-540,"elapsed":9,"user":{"displayName":"김채원","userId":"06191165418472654659"}},"outputId":"dd4e4e34-181d-4652-a5a9-9d20b8b6b88d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(256, 280, 280, 3)"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["mix_label.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMoOEKJVChHp","executionInfo":{"status":"ok","timestamp":1679453337504,"user_tz":-540,"elapsed":9,"user":{"displayName":"김채원","userId":"06191165418472654659"}},"outputId":"7cb45268-c321-42fc-88a6-a23208c895b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(256, 1)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["np.unique(mix_label, return_counts = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nkd0NlAUKjLy","executionInfo":{"status":"ok","timestamp":1679453337504,"user_tz":-540,"elapsed":6,"user":{"displayName":"김채원","userId":"06191165418472654659"}},"outputId":"9e466636-fa94-4c0f-c7a8-76a43afb513c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0, 1]), array([ 88, 168]))"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["from PIL import Image\n","\n","i = 0\n","for data, label in zip(mix_data,mix_label):\n","    if label == 1:\n","        cv2.imwrite(f'{aug_dataset_path}/ab_mixup_{i}.jpg',data*255)\n","        i += 1\n","    else:\n","        cv2.imwrite(f'{aug_dataset_path}/mixup_{i}.jpg',data*255)\n","        i += 1"],"metadata":{"id":"g3LBfS7uEgsk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(os.listdir(aug_dataset_path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhWHVuvwEgyh","executionInfo":{"status":"ok","timestamp":1679453349362,"user_tz":-540,"elapsed":17,"user":{"displayName":"김채원","userId":"06191165418472654659"}},"outputId":"ec1156bc-efba-4e75-bc6a-794a150b1cdd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["256"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# 시각화\n","# Let's preview 9 samples from the dataset\n","sample_images, sample_labels = next(iter(train_ds_mu))\n","plt.figure(figsize=(10, 10))\n","for i, (image, label) in enumerate(zip(sample_images[:9], sample_labels[:9])):\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(image.numpy().squeeze())\n","    print(label.numpy().tolist())\n","    print(\"*******************************************\")\n","    plt.axis(\"off\")"],"metadata":{"id":"osQPh8p79ed2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uQL_kjx3Sl_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3hB9d2UqCVNw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9NhBZM6ZCVS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_BXbr1SBCVVt"},"execution_count":null,"outputs":[]}]}